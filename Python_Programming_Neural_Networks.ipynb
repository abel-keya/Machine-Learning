{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Python Programming: Neural Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abel-keya/Machine-Learning/blob/master/Python_Programming_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R6WscQk9KpW",
        "colab_type": "text"
      },
      "source": [
        "##<font color='green'>Python Programming: Neural Networks</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjaOiyuz9nT9",
        "colab_type": "text"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR571VKrriCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing libraries\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Import a standardization library\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Import an Multi-Layer Perceptron Classifier model estimator from Scikit-Learn's neural_network library\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwM2CzLfD7-b",
        "colab_type": "text"
      },
      "source": [
        "### Example 1: Wine Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcaUwpSUEJpO",
        "colab_type": "text"
      },
      "source": [
        "In this example we are going to use Neural networks to classifer a wine that has been grown from the sam e region in Italy into three possible cultivars based on various chemical feautures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpdVtV3UCoVT",
        "colab_type": "text"
      },
      "source": [
        "**Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-s_-r7TCu10",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "ee91d993-a61d-4398-a8eb-085b34f68430"
      },
      "source": [
        "# Loading data\n",
        "wine = pd.read_csv('http://bit.ly/wine_classification_data', names =[\"Cultivator\", \"Alchol\", \"Malic_Acid\", \"Ash\", \"Alcalinity_of_Ash\", \"Magnesium\", \"Total_phenols\", \"Falvanoids\", \"Nonflavanoid_phenols\", \"Proanthocyanins\", \"Color_intensity\", \"Hue\", \"OD280\", \"Proline\"])\n",
        "wine.head()\n",
        "# wine.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cultivator</th>\n",
              "      <th>Alchol</th>\n",
              "      <th>Malic_Acid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity_of_Ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total_phenols</th>\n",
              "      <th>Falvanoids</th>\n",
              "      <th>Nonflavanoid_phenols</th>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <th>Color_intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>OD280</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Cultivator  Alchol  Malic_Acid   Ash  ...  Color_intensity   Hue  OD280  Proline\n",
              "0           1   14.23        1.71  2.43  ...             5.64  1.04   3.92     1065\n",
              "1           1   13.20        1.78  2.14  ...             4.38  1.05   3.40     1050\n",
              "2           1   13.16        2.36  2.67  ...             5.68  1.03   3.17     1185\n",
              "3           1   14.37        1.95  2.50  ...             7.80  0.86   3.45     1480\n",
              "4           1   13.24        2.59  2.87  ...             4.32  1.04   2.93      735\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHH6gQy3DtHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting up our labels and features\n",
        "X =  wine.drop('Cultivator', axis = 1)\n",
        "y = wine[\"Cultivator\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hhUKK9xDacn",
        "colab_type": "text"
      },
      "source": [
        "**Split Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWTvZ6uUDZCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i08BRcXbGhNB",
        "colab_type": "text"
      },
      "source": [
        "**Normalization of data**\n",
        "\n",
        "Multi-Layer Perceptron class is very sensitve to feature scaling, thus it is always a good habit to sclae our data.\n",
        "\n",
        "However, feature scaling is only fitted on the training data and not the test data. This is due to the fact that in real world data is not scaled and the major purpose of neural networks is to make predictions on real world data. Hence we try as musch as possible to keep the test data real. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qwVg5PYNyRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fitting the scaler\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Applying the transformation to the data\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_fJiR6IPEhd",
        "colab_type": "text"
      },
      "source": [
        "**Training the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7fLrj3IPJg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f92293d8-ccad-4f8c-f692-6ba356aeb8a4"
      },
      "source": [
        "# Creating an instance of the model\n",
        "# The MLPClassifier takes in a number of arguments but we are only going to use one for now which is hidden_layer_sizes. we will explore the rest of the arguments in the next session after we have looked at optimization\n",
        "# For the hidden_layer_sizes we pass in a tuple that consist the number of neurons we want each layer to have. The nth number of the tuple represents the number of layers you want your network to have.\n",
        "# For us, we will choose 3 layers with the same number of neurons\n",
        "# YOu can read more on the MLPClasssifier here: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes = (13, 13,13), max_iter = 500)\n",
        "\n",
        "# fitting the data\n",
        "mlp.fit(X_train,y_train)\n",
        "\n",
        "#By default the activation is set to ReLu function but you can always change it to suit your needs. You can always check the other option available from the documentation"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(13, 13, 13), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loiqqK6wSjk2",
        "colab_type": "text"
      },
      "source": [
        "**Prediction and Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLNUuvA1Sqk-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f1388670-98a5-4575-efdf-46988191b961"
      },
      "source": [
        "# Now that we have our model in place, let's do the prediction\n",
        "\n",
        "pred = mlp.predict(X_test)\n",
        "\n",
        "\n",
        "# Evaluating the performance of ur model\n",
        "print (confusion_matrix(y_test,pred))\n",
        "\n",
        "print('-----------------------------------------------')\n",
        "\n",
        "print(classification_report(y_test,pred))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10  0  0]\n",
            " [ 0 14  4]\n",
            " [ 0  0  8]]\n",
            "-----------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       1.00      0.78      0.88        18\n",
            "           3       0.67      1.00      0.80         8\n",
            "\n",
            "    accuracy                           0.89        36\n",
            "   macro avg       0.89      0.93      0.89        36\n",
            "weighted avg       0.93      0.89      0.89        36\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luQ-J4xBUa35",
        "colab_type": "text"
      },
      "source": [
        "**Conclusion**\n",
        "\n",
        "From the results we can see that we have only missclassified two bottles of wine in our test data.\n",
        "\n",
        "One downside using Multi-Layer Perception model is that it's dificult to interpret the model itself. The weights and biases are not easily interpretable in relatin to which features are important to the model itself.\n",
        "\n",
        "However, we can be able to extract the weights and biases after training our model.\n",
        "\n",
        "\n",
        "\n",
        "**PS**: Try using different activation functions and see which one given you the best results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btvMNTySWC5F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50ac7193-b343-473c-c832-5352270360af"
      },
      "source": [
        "# Extracting the weights and bias vectors\n",
        "\n",
        "# Checking the number of weights \n",
        "len(mlp.coefs_) \n",
        "\n",
        "# Checking the number of biases \n",
        "len(mlp.intercepts_) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18lsiAZ5XMrR",
        "colab_type": "text"
      },
      "source": [
        "## <font color='green'>Challenge 1</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klT46BO6XgdI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "de40f58b-9420-4c86-d5f4-aaf8530c0144"
      },
      "source": [
        "# Apply neural network technique to the Iris dataset we used in SVM to classify the different classes of flowers. Compare the performance of SVM to that of neural networks and see which is better\n",
        "#  Dataset Url ----> http://bit.ly/Iris_flower_data\n",
        "\n",
        "url = \"http://bit.ly/Iris_flower_data\"\n",
        "data = pd.read_csv(url)\n",
        "data.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal-length</th>\n",
              "      <th>sepal-width</th>\n",
              "      <th>petal-length</th>\n",
              "      <th>petal-width</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal-length  sepal-width  petal-length  petal-width        Class\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2R7SRC01Ufa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting up our labels and features\n",
        "X =  data.drop('Class', axis = 1)\n",
        "y = data[\"Class\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7IB5gHM2Ie8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjG55xIz2Tdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fitting the scaler\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Applying the transformation to the data\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4kjTXx72gny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "10b84aa9-b158-4687-936e-597ec3153197"
      },
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes = (13, 13,13), max_iter = 500)\n",
        "\n",
        "# fitting the data\n",
        "mlp.fit(X_train,y_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(13, 13, 13), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yad-hxvn2wW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "52d52d67-b8cb-4a78-ee34-8e285b3d007f"
      },
      "source": [
        "# Now that we have our model in place, let's do the prediction\n",
        "\n",
        "pred = mlp.predict(X_test)\n",
        "\n",
        "\n",
        "# Evaluating the performance of ur model\n",
        "print (confusion_matrix(y_test,pred))\n",
        "\n",
        "print('-----------------------------------------------')\n",
        "\n",
        "print(classification_report(y_test,pred))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10  0  0]\n",
            " [ 0 12  1]\n",
            " [ 0  0  7]]\n",
            "-----------------------------------------------\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00        10\n",
            "Iris-versicolor       1.00      0.92      0.96        13\n",
            " Iris-virginica       0.88      1.00      0.93         7\n",
            "\n",
            "       accuracy                           0.97        30\n",
            "      macro avg       0.96      0.97      0.96        30\n",
            "   weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5stnAkXZ25PK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca00fa28-d072-4352-880c-f9d85e517c05"
      },
      "source": [
        "# Extracting the weights and bias vectors\n",
        "\n",
        "# Checking the number of weights \n",
        "len(mlp.coefs_) \n",
        "\n",
        "# Checking the number of biases \n",
        "len(mlp.intercepts_)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLvvIc8VFEiO",
        "colab_type": "text"
      },
      "source": [
        "## <font color='green'>Challenge 2\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1brz62LrFIbd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "e2d85cb5-19dd-485f-f40e-0950b9bc09ce"
      },
      "source": [
        "# Use the following dataset to classsify if a patient has diabetes or not\n",
        "\n",
        "# Dataset Url -------> http://bit.ly/diabetes_data\n",
        "url2 = \"http://bit.ly/diabetes_data\"\n",
        "diabetes = pd.read_csv(url2)\n",
        "diabetes"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies  Glucose  ...  Age  Outcome\n",
              "0              6      148  ...   50        1\n",
              "1              1       85  ...   31        0\n",
              "2              8      183  ...   32        1\n",
              "3              1       89  ...   21        0\n",
              "4              0      137  ...   33        1\n",
              "..           ...      ...  ...  ...      ...\n",
              "763           10      101  ...   63        0\n",
              "764            2      122  ...   27        0\n",
              "765            5      121  ...   30        0\n",
              "766            1      126  ...   47        1\n",
              "767            1       93  ...   23        0\n",
              "\n",
              "[768 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au0E6QT23pmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting up our labels and features\n",
        "X =  diabetes.drop('Outcome', axis = 1)\n",
        "y = diabetes[\"Outcome\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP-H_hYZ4P8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlX_Fnng4b6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fitting the scaler\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Applying the transformation to the data\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18oX-Inj4lkQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "e2aea217-6d4a-405a-8e35-14512cdd9952"
      },
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes = (50, 50,50), max_iter = 100)\n",
        "\n",
        "# fitting the data\n",
        "mlp.fit(X_train,y_train)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(50, 50, 50), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcVJuLHI44Nd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "fef4a42b-2ac0-4f9f-c4cf-50023b8159d1"
      },
      "source": [
        "# Now that we have our model in place, let's do the prediction\n",
        "\n",
        "pred = mlp.predict(X_test)\n",
        "\n",
        "\n",
        "# Evaluating the performance of ur model\n",
        "print (confusion_matrix(y_test,pred))\n",
        "\n",
        "print('-----------------------------------------------')\n",
        "\n",
        "print(classification_report(y_test,pred))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[81 14]\n",
            " [29 30]]\n",
            "-----------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.85      0.79        95\n",
            "           1       0.68      0.51      0.58        59\n",
            "\n",
            "    accuracy                           0.72       154\n",
            "   macro avg       0.71      0.68      0.69       154\n",
            "weighted avg       0.72      0.72      0.71       154\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOWQfApE7caZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bea8f8ec-6c43-4a36-fc3b-9fc088fa49f0"
      },
      "source": [
        "# Extracting the weights and bias vectors\n",
        "\n",
        "# Checking the number of weights \n",
        "len(mlp.coefs_) \n",
        "\n",
        "# Checking the number of biases \n",
        "len(mlp.intercepts_)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    }
  ]
}